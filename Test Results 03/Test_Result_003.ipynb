{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coQtB-fBMwnc",
        "outputId": "51a7b331-787c-4798-bed6-cdffab2eea9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.19.3)\n",
            "Requirement already satisfied: pywavelets in /usr/local/lib/python3.10/dist-packages (1.4.1)\n",
            "Collecting leidenalg\n",
            "  Downloading leidenalg-0.10.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.11.3)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.2.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2023.9.26)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (23.2)\n",
            "Collecting igraph<0.11,>=0.10.0 (from leidenalg)\n",
            "  Downloading igraph-0.10.8-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting texttable>=1.6.2 (from igraph<0.11,>=0.10.0->leidenalg)\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Installing collected packages: texttable, igraph, leidenalg\n",
            "Successfully installed igraph-0.10.8 leidenalg-0.10.1 texttable-1.7.0\n"
          ]
        }
      ],
      "source": [
        "# Install necessary packages if not already installed\n",
        "!pip install opencv-python numpy scikit-image pywavelets leidenalg\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage import feature\n",
        "from pywt import dwt2\n",
        "from leidenalg import find_partition\n",
        "import time\n",
        "import psutil\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cdW3VH3PIKv",
        "outputId": "615cf648-d881-419c-90e7-54e02e60ea5e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_CCFV(color_feature, edge_feature, wavelet_feature):\n",
        "    # Step 1: Initialization\n",
        "    X = color_feature.flatten()  # Color feature vector\n",
        "    Y = np.concatenate([edge_feature.flatten(), wavelet_feature.flatten()])  # Combined feature vector\n",
        "\n",
        "    # Step 2: Covariance Matrices\n",
        "    n = len(X)\n",
        "    mean_X = np.mean(X)\n",
        "    mean_Y = np.mean(Y)\n",
        "\n",
        "    Sxx = np.cov(X, rowvar=False)\n",
        "    Syy = np.cov(Y, rowvar=False)\n",
        "    Sxy = np.cov(X, Y, rowvar=False)\n",
        "\n",
        "    # Step 3: Compute Transformation Matrices G1 and G2\n",
        "    G1 = np.linalg.inv(np.sqrt(Sxx)).dot(Sxy).dot(np.linalg.inv(Syy)).dot(Sxy.T).dot(np.linalg.inv(np.sqrt(Sxx)))\n",
        "    G2 = np.linalg.inv(np.sqrt(Syy)).dot(Sxy.T).dot(np.linalg.inv(Sxx)).dot(Sxy).dot(np.linalg.inv(np.sqrt(Syy)))\n",
        "\n",
        "    # Step 4: Compute Eigen Vectors and Rank\n",
        "    _, u = np.linalg.eig(G1)\n",
        "    _, v = np.linalg.eig(G2)\n",
        "    r = np.linalg.matrix_rank(Sxy)\n",
        "\n",
        "    # Step 5: Choose Canonical Variables\n",
        "    d = 100  # Choose the first d pairs of eigen vectors\n",
        "    Wx = np.linalg.inv(np.sqrt(Sxx)).dot(u[:, :d])\n",
        "    Wy = np.linalg.inv(np.sqrt(Syy)).dot(v[:, :d])\n",
        "\n",
        "    # Step 6: Compute Canonically Correlated Feature Vector (CCFV)\n",
        "    CCFV = (Wx.T.dot(X) + Wy.T.dot(Y)).reshape(-1, 1)\n",
        "\n",
        "    return CCFV\n",
        "\n",
        "def extract_frames(video_path):\n",
        "    # Create a directory to store extracted frames\n",
        "    frames_dir = \"/content/gdrive/MyDrive/Video-Keyframe-Extraction-through-Canonical-Correlation-Analysis-and-Graph-Modularity-main/Test Results 03/extracted_frames\"\n",
        "    os.makedirs(frames_dir, exist_ok=True)\n",
        "\n",
        "    # Read the video and extract frames\n",
        "    video = cv2.VideoCapture(video_path)\n",
        "    frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    for frame_number in range(frame_count):\n",
        "        ret, frame = video.read()\n",
        "        if ret:\n",
        "            frame_path = os.path.join(frames_dir, f\"frame_{frame_number}.jpg\")\n",
        "            cv2.imwrite(frame_path, frame)\n",
        "\n",
        "    video.release()\n",
        "\n",
        "    return frames_dir\n",
        "\n",
        "def extract_features(frames):\n",
        "    color_features = []\n",
        "    edge_features = []\n",
        "    wavelet_features = []\n",
        "\n",
        "    for frame in frames:\n",
        "        # Extract Color feature (for example, using histogram)\n",
        "        color_feature = cv2.calcHist([frame], [0, 1, 2], None, [256, 256, 256], [0, 256, 0, 256, 0, 256])\n",
        "\n",
        "        # Extract Edge feature (for example, using Canny edge detector)\n",
        "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        edge_feature = feature.canny(gray_frame)\n",
        "\n",
        "        # Extract Wavelet feature (for example, using Haar wavelet transform)\n",
        "        coeffs = dwt2(gray_frame, 'haar')\n",
        "        wavelet_feature = np.concatenate((coeffs[0].flatten(), coeffs[1][0].flatten(), coeffs[1][1].flatten(), coeffs[1][2].flatten()))\n",
        "\n",
        "        color_features.append(color_feature)\n",
        "        edge_features.append(edge_feature)\n",
        "        wavelet_features.append(wavelet_feature)\n",
        "\n",
        "    return np.array(color_features), np.array(edge_features), np.array(wavelet_features)\n",
        "\n",
        "def identify_keyframes(frames_dir, threshold=0.9):\n",
        "    # Get the list of frame files\n",
        "    frame_files = sorted(os.listdir(frames_dir))\n",
        "\n",
        "    if not frame_files:\n",
        "        raise ValueError(\"No frames found in the frames directory\")\n",
        "\n",
        "    # Initialize keyframes list\n",
        "    keyframes = [frame_files[0]]  # Always add the first frame as a keyframe\n",
        "\n",
        "    for i in range(1, len(frame_files)):\n",
        "        current_frame_path = os.path.join(frames_dir, frame_files[i])\n",
        "        prev_frame_path = os.path.join(frames_dir, frame_files[i - 1])\n",
        "\n",
        "        # Read frames\n",
        "        current_frame = cv2.imread(current_frame_path)\n",
        "        prev_frame = cv2.imread(prev_frame_path)\n",
        "\n",
        "        # Extract features\n",
        "        current_color, current_edge, current_wavelet = extract_features([current_frame])\n",
        "        prev_color, prev_edge, prev_wavelet = extract_features([prev_frame])\n",
        "\n",
        "        # Calculate Canonically Correlated Feature Vector (CCFV)\n",
        "        ccfv = calculate_CCFV(current_color, current_edge, current_wavelet)\n",
        "        prev_ccfv = calculate_CCFV(prev_color, prev_edge, prev_wavelet)\n",
        "\n",
        "        # Calculate Euclidean distance between CCFVs\n",
        "        distance = np.linalg.norm(ccfv - prev_ccfv)\n",
        "\n",
        "        # Check if the distance is below the threshold\n",
        "        if distance > threshold:\n",
        "            keyframes.append(frame_files[i])\n",
        "\n",
        "    return keyframes\n",
        "\n",
        "def summarize_video(video_path, num_frames, batch_size=100):\n",
        "    # Extract frames from the video\n",
        "    frames_dir = extract_frames(video_path)\n",
        "\n",
        "    # Identify keyframes based on Multi-feature Fusion algorithm\n",
        "    keyframes = identify_keyframes(frames_dir)\n",
        "\n",
        "    # Create the \"process_frames\" directory and move keyframes there\n",
        "    create_process_frames_directory(keyframes, frames_dir)\n",
        "\n",
        "    # Perform clustering using Leiden graph modularity clustering algorithm\n",
        "    labels = leiden_cluster(frames_dir, keyframes, num_frames, batch_size)\n",
        "\n",
        "    # Get selected frames based on clustering labels\n",
        "    selected_frames = get_selected_frames(frames_dir, keyframes, labels)\n",
        "\n",
        "    return selected_frames\n",
        "\n",
        "def create_process_frames_directory(keyframes, frames_dir):\n",
        "    # Create a directory to store the identified keyframes\n",
        "    process_frames_dir = os.path.join(frames_dir, \"process_frames\")\n",
        "    os.makedirs(process_frames_dir, exist_ok=True)\n",
        "\n",
        "    # Copy keyframes to the process_frames directory\n",
        "    for keyframe in keyframes:\n",
        "        source_path = os.path.join(frames_dir, keyframe)\n",
        "        target_path = os.path.join(process_frames_dir, keyframe)\n",
        "        try:\n",
        "            os.rename(source_path, target_path)\n",
        "        except FileNotFoundError:\n",
        "            continue\n",
        "\n",
        "def leiden_cluster(frames_dir, keyframes, num_frames, batch_size):\n",
        "    # Perform clustering to obtain the labels\n",
        "    labels = []\n",
        "\n",
        "    # Process frames in batches\n",
        "    for i in range(0, len(keyframes), batch_size):\n",
        "        batch_frames = []\n",
        "        for j in range(i, min(i + batch_size, len(keyframes))):\n",
        "            frame_path = os.path.join(frames_dir, \"process_frames\", keyframes[j])\n",
        "            frame = cv2.imread(frame_path)\n",
        "            batch_frames.append(frame)\n",
        "\n",
        "        # Extract features from the batch of frames\n",
        "        color_features, edge_features, wavelet_features = extract_features(batch_frames)\n",
        "\n",
        "        # Calculate Canonically Correlated Feature Vectors (CCFVs)\n",
        "        ccfvs = np.array([calculate_CCFV(color, edge, wavelet) for color, edge, wavelet in\n",
        "                          zip(color_features, edge_features, wavelet_features)])\n",
        "\n",
        "        # Perform clustering using Leiden algorithm\n",
        "        partition = find_partition(ccfvs, resolution_parameter=1.0)\n",
        "\n",
        "        # Append cluster labels to the overall labels list\n",
        "        labels.extend(partition)\n",
        "\n",
        "    return labels\n",
        "\n",
        "def get_selected_frames(frames_dir, keyframes, labels):\n",
        "    selected_frames = []\n",
        "\n",
        "    # Iterate over keyframes and corresponding labels\n",
        "    for keyframe, label in zip(keyframes, labels):\n",
        "        if label == 0:  # Select frames associated with the specific cluster (label)\n",
        "            selected_frames.append(os.path.join(frames_dir, \"process_frames\", keyframe))\n",
        "\n",
        "    return selected_frames\n",
        "\n",
        "def create_summarized_video(input_video_path, output_video_path, selected_frames):\n",
        "    # Get the video properties from the input video\n",
        "    input_video = cv2.VideoCapture(input_video_path)\n",
        "    frame_width = int(input_video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    frame_height = int(input_video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(input_video.get(cv2.CAP_PROP_FPS))\n",
        "    video_codec = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "\n",
        "    # Create the output video writer\n",
        "    output_video = cv2.VideoWriter(output_video_path, video_codec, fps, (frame_width, frame_height))\n",
        "\n",
        "    # Read the selected frames and write them to the output video\n",
        "    for frame_path in selected_frames:\n",
        "        frame = cv2.imread(frame_path)\n",
        "        output_video.write(frame)\n",
        "\n",
        "    # Release resources\n",
        "    input_video.release()\n",
        "    output_video.release()\n",
        "\n",
        "def get_time_complexity():\n",
        "    start_time = time.time()\n",
        "    # Input video path\n",
        "    input_video_path = '/content/gdrive/MyDrive/Video-Keyframe-Extraction-through-Canonical-Correlation-Analysis-and-Graph-Modularity-main/Test Results 03/Surveilance_camera_test03.mp4'\n",
        "\n",
        "    # Specify the desired number of resultant frames\n",
        "    num_frames = 10\n",
        "\n",
        "    try:\n",
        "        # Summarize the video and obtain selected frames\n",
        "        selected_frames = summarize_video(input_video_path, num_frames)\n",
        "\n",
        "        # Output video path\n",
        "        output_video_path = '/content/gdrive/MyDrive/Video-Keyframe-Extraction-through-Canonical-Correlation-Analysis-and-Graph-Modularity-main/Test Results 03/Summarized_Surveilance_camera_test03.mp4'\n",
        "\n",
        "        # Create the summarized output video\n",
        "        create_summarized_video(input_video_path, output_video_path, selected_frames)\n",
        "\n",
        "        print(\"Video summarization completed successfully!\")\n",
        "    except ValueError as e:\n",
        "        print(f\"Video summarization failed: {str(e)}\")\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    return elapsed_time\n",
        "\n",
        "def get_space_complexity():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    memory_usage = process.memory_info().rss  # in bytes\n",
        "    memory_usage_mb = memory_usage / (1024 ** 2)  # convert to megabytes\n",
        "    return memory_usage_mb"
      ],
      "metadata": {
        "id": "d50MwCmVPMOF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    time_complexity = get_time_complexity()\n",
        "    space_complexity = get_space_complexity()\n",
        "\n",
        "    print(f\"Overall Time Complexity: {time_complexity} seconds\")\n",
        "    print(f\"Overall Space Complexity: {space_complexity} MB\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCDIVjwzPYst",
        "outputId": "9d4777ec-84bf-4301-88ce-ed8c18d0b7db"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video summarization failed: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 16777216 and the array at index 1 has size 460800\n",
            "Overall Time Complexity: 45.601526975631714 seconds\n",
            "Overall Space Complexity: 187.76171875 MB\n"
          ]
        }
      ]
    }
  ]
}