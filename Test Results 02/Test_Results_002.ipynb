{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zB2a_NL4HsdF"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage import feature\n",
        "import pywt\n",
        "import time\n",
        "import os\n",
        "import psutil\n",
        "import community  # Louvain clustering"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faPJTV42KaA8",
        "outputId": "b1f5726c-57d0-4b67-a824-978d08ae0689"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "!pip install opencv-python scikit-image scikit-learn pywavelets python-louvain\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage import feature\n",
        "import pywt\n",
        "import time\n",
        "import os\n",
        "import psutil\n",
        "import community  # Louvain clustering"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKDqg7s3KgWK",
        "outputId": "d19b3c56-5eac-4386-a061-39738f754cea"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.19.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: pywavelets in /usr/local/lib/python3.10/dist-packages (1.4.1)\n",
            "Requirement already satisfied: python-louvain in /usr/local/lib/python3.10/dist-packages (0.16)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.11.3)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.2.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2023.9.26)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (23.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_CCFV(color_feature, edge_feature, wavelet_feature):\n",
        "    # Step 1: Initialization\n",
        "    X = color_feature.flatten()  # Color feature vector\n",
        "    Y = np.concatenate([edge_feature.flatten(), wavelet_feature.flatten()])  # Combined feature vector\n",
        "\n",
        "    # Step 2: Covariance Matrices\n",
        "    n = len(X)\n",
        "    mean_X = np.mean(X)\n",
        "    mean_Y = np.mean(Y)\n",
        "\n",
        "    Sxx = np.cov(X, rowvar=False)\n",
        "    Syy = np.cov(Y, rowvar=False)\n",
        "    Sxy = np.cov(X, Y, rowvar=False)\n",
        "\n",
        "    # Step 3: Compute Transformation Matrices G1 and G2\n",
        "    G1 = np.linalg.inv(np.sqrt(Sxx)).dot(Sxy).dot(np.linalg.inv(Syy)).dot(Sxy.T).dot(np.linalg.inv(np.sqrt(Sxx)))\n",
        "    G2 = np.linalg.inv(np.sqrt(Syy)).dot(Sxy.T).dot(np.linalg.inv(Sxx)).dot(Sxy).dot(np.linalg.inv(np.sqrt(Syy)))\n",
        "\n",
        "    # Step 4: Compute Eigen Vectors and Rank\n",
        "    _, u = np.linalg.eig(G1)\n",
        "    _, v = np.linalg.eig(G2)\n",
        "    r = np.linalg.matrix_rank(Sxy)\n",
        "\n",
        "    # Step 5: Choose Canonical Variables\n",
        "    d = 100  # Choose the first d pairs of eigen vectors\n",
        "    Wx = np.linalg.inv(np.sqrt(Sxx)).dot(u[:, :d])\n",
        "    Wy = np.linalg.inv(np.sqrt(Syy)).dot(v[:, :d])\n",
        "\n",
        "    # Step 6: Compute Canonically Correlated Feature Vector (CCFV)\n",
        "    CCFV = (Wx.T.dot(X) + Wy.T.dot(Y)).reshape(-1, 1)\n",
        "\n",
        "    return CCFV"
      ],
      "metadata": {
        "id": "aQFBS9wcKohK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_frames(video_path):\n",
        "    # Create a directory to store extracted frames\n",
        "    frames_dir = \"/content/drive/MyDrive/Video-Keyframe-Extraction-through-Canonical-Correlation-Analysis-and-Graph-Modularity-main/Test Results 02/extracted_frames\"\n",
        "    os.makedirs(frames_dir, exist_ok=True)\n",
        "\n",
        "    # Read the video and extract frames\n",
        "    video = cv2.VideoCapture(video_path)\n",
        "    frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    for frame_number in range(frame_count):\n",
        "        ret, frame = video.read()\n",
        "        if ret:\n",
        "            frame_path = os.path.join(frames_dir, f\"frame_{frame_number}.jpg\")\n",
        "            cv2.imwrite(frame_path, frame)\n",
        "\n",
        "    video.release()\n",
        "\n",
        "    return frames_dir"
      ],
      "metadata": {
        "id": "K49PiSluKtKa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(frames):\n",
        "    color_features = []\n",
        "    edge_features = []\n",
        "    wavelet_features = []\n",
        "\n",
        "    for frame in frames:\n",
        "        # Extract Color feature (for example, using histogram)\n",
        "        color_feature = cv2.calcHist([frame], [0, 1, 2], None, [256, 256, 256], [0, 256, 0, 256, 0, 256])\n",
        "\n",
        "        # Extract Edge feature (for example, using Canny edge detector)\n",
        "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        edge_feature = feature.canny(gray_frame)\n",
        "\n",
        "        # Extract Wavelet feature (for example, using Haar wavelet transform)\n",
        "        coeffs = pywt.dwt2(gray_frame, 'haar')\n",
        "        wavelet_feature = np.concatenate((coeffs[0].flatten(), coeffs[1][0].flatten(), coeffs[1][1].flatten(), coeffs[1][2].flatten()))\n",
        "\n",
        "        color_features.append(color_feature)\n",
        "        edge_features.append(edge_feature)\n",
        "        wavelet_features.append(wavelet_feature)\n",
        "\n",
        "    return np.array(color_features), np.array(edge_features), np.array(wavelet_features)"
      ],
      "metadata": {
        "id": "7K1U7wWYKxKK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def identify_keyframes(frames_dir, threshold=0.9):\n",
        "    # Get the list of frame files\n",
        "    frame_files = sorted(os.listdir(frames_dir))\n",
        "\n",
        "    if not frame_files:\n",
        "        raise ValueError(\"No frames found in the frames directory\")\n",
        "\n",
        "    # Initialize keyframes list\n",
        "    keyframes = [frame_files[0]]  # Always add the first frame as a keyframe\n",
        "\n",
        "    for i in range(1, len(frame_files)):\n",
        "        current_frame_path = os.path.join(frames_dir, frame_files[i])\n",
        "        prev_frame_path = os.path.join(frames_dir, frame_files[i - 1])\n",
        "\n",
        "        # Read frames\n",
        "        current_frame = cv2.imread(current_frame_path)\n",
        "        prev_frame = cv2.imread(prev_frame_path)\n",
        "\n",
        "        # Extract features\n",
        "        current_color, current_edge, current_wavelet = extract_features([current_frame])\n",
        "        prev_color, prev_edge, prev_wavelet = extract_features([prev_frame])\n",
        "\n",
        "        # Calculate Canonically Correlated Feature Vector (CCFV)\n",
        "        ccfv = calculate_CCFV(current_color, current_edge, current_wavelet)\n",
        "        prev_ccfv = calculate_CCFV(prev_color, prev_edge, prev_wavelet)\n",
        "\n",
        "        # Calculate Euclidean distance between CCFVs\n",
        "        distance = np.linalg.norm(ccfv - prev_ccfv)\n",
        "\n",
        "        # Check if the distance is below the threshold\n",
        "        if distance > threshold:\n",
        "            keyframes.append(frame_files[i])\n",
        "\n",
        "    return keyframes"
      ],
      "metadata": {
        "id": "VkkH5fOoK0tC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_video(video_path, num_frames, batch_size=100):\n",
        "    # Extract frames from the video\n",
        "    frames_dir = extract_frames(video_path)\n",
        "\n",
        "    # Identify keyframes based on Multi-feature Fusion algorithm\n",
        "    keyframes = identify_keyframes(frames_dir)\n",
        "\n",
        "    # Create the \"process_frames\" directory and move keyframes there\n",
        "    create_process_frames_directory(keyframes, frames_dir)\n",
        "\n",
        "    # Perform clustering using Louvain graph modularity clustering algorithm\n",
        "    labels = louvain_cluster(frames_dir, keyframes, num_frames, batch_size)\n",
        "\n",
        "    # Get selected frames based on clustering labels\n",
        "    selected_frames = get_selected_frames(frames_dir, keyframes, labels)\n",
        "\n",
        "    return selected_frames"
      ],
      "metadata": {
        "id": "Pjt_swNBK5KC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_process_frames_directory(keyframes, frames_dir):\n",
        "    # Create a directory to store the identified keyframes\n",
        "    process_frames_dir = os.path.join(frames_dir, \"process_frames\")\n",
        "    os.makedirs(process_frames_dir, exist_ok=True)\n",
        "\n",
        "    # Copy keyframes to the process_frames directory\n",
        "    for keyframe in keyframes:\n",
        "        source_path = os.path.join(frames_dir, keyframe)\n",
        "        target_path = os.path.join(process_frames_dir, keyframe)\n",
        "        try:\n",
        "            os.rename(source_path, target_path)\n",
        "        except FileNotFoundError:\n",
        "            continue"
      ],
      "metadata": {
        "id": "Y8XCFGscK9oy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def louvain_cluster(frames_dir, keyframes, num_frames, batch_size):\n",
        "    # Perform clustering to obtain the labels\n",
        "    labels = []\n",
        "\n",
        "    # Process frames in batches\n",
        "    for i in range(0, len(keyframes), batch_size):\n",
        "        batch_frames = []\n",
        "        for j in range(i, min(i + batch_size, len(keyframes))):\n",
        "            frame_path = os.path.join(frames_dir, \"process_frames\", keyframes[j])\n",
        "            frame = cv2.imread(frame_path)\n",
        "            batch_frames.append(frame)\n",
        "\n",
        "        # Extract features from the batch of frames\n",
        "        color_features, edge_features, wavelet_features = extract_features(batch_frames)\n",
        "\n",
        "        # Calculate Canonically Correlated Feature Vectors (CCFVs)\n",
        "        ccfvs = np.array([calculate_CCFV(color, edge, wavelet) for color, edge, wavelet in\n",
        "                          zip(color_features, edge_features, wavelet_features)])\n",
        "\n",
        "        # Perform clustering using Louvain algorithm\n",
        "        cluster_labels = louvain_clustering(ccfvs)\n",
        "\n",
        "        # Append cluster labels to the overall labels list\n",
        "        labels.extend(cluster_labels)\n",
        "\n",
        "    return labels"
      ],
      "metadata": {
        "id": "zFM9KNALLGEz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def louvain_clustering(ccfvs):\n",
        "    # Calculate distance matrix\n",
        "    distance_matrix = np.linalg.norm(ccfvs[:, None] - ccfvs, axis=-1)\n",
        "\n",
        "    # Apply Louvain clustering\n",
        "    partition = community.best_partition(1 / (1 + distance_matrix))\n",
        "\n",
        "    # Extract cluster labels\n",
        "    labels = list(partition.values())\n",
        "\n",
        "    return labels"
      ],
      "metadata": {
        "id": "OYDV0OM2LLAl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_selected_frames(frames_dir, keyframes, labels):\n",
        "    selected_frames = []\n",
        "\n",
        "    # Iterate over keyframes and corresponding labels\n",
        "    for keyframe, label in zip(keyframes, labels):\n",
        "        if label == 0:  # Select frames associated with the specific cluster (label)\n",
        "            selected_frames.append(os.path.join(frames_dir, \"process_frames\", keyframe))\n",
        "\n",
        "    return selected_frames"
      ],
      "metadata": {
        "id": "IKzpji7aLN9L"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_summarized_video(input_video_path, output_video_path, selected_frames):\n",
        "    # Get the video properties from the input video\n",
        "    input_video = cv2.VideoCapture(input_video_path)\n",
        "    frame_width = int(input_video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    frame_height = int(input_video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(input_video.get(cv2.CAP_PROP_FPS))\n",
        "    video_codec = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "\n",
        "    # Create the output video writer\n",
        "    output_video = cv2.VideoWriter(output_video_path, video_codec, fps, (frame_width, frame_height))\n",
        "\n",
        "    # Read the selected frames and write them to the output video\n",
        "    for frame_path in selected_frames:\n",
        "        frame = cv2.imread(frame_path)\n",
        "        output_video.write(frame)\n",
        "\n",
        "    # Release resources\n",
        "    input_video.release()\n",
        "    output_video.release()"
      ],
      "metadata": {
        "id": "1s22oFEiLRRq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_time_complexity():\n",
        "    start_time = time.time()\n",
        "    # Input video path\n",
        "    input_video_path = '/content/drive/MyDrive/Video-Keyframe-Extraction-through-Canonical-Correlation-Analysis-and-Graph-Modularity-main/Test Results 02/Surveilance_camera_test02.mp4'\n",
        "\n",
        "    # Specify the desired number of resultant frames\n",
        "    num_frames = 10\n",
        "\n",
        "    try:\n",
        "        # Summarize the video and obtain selected frames\n",
        "        selected_frames = summarize_video(input_video_path, num_frames)\n",
        "\n",
        "        # Output video path\n",
        "        output_video_path = '/content/drive/MyDrive/Video-Keyframe-Extraction-through-Canonical-Correlation-Analysis-and-Graph-Modularity-main/Test Results 02/Summarized_Surveilance_camera_test02.mp4'\n",
        "\n",
        "        # Create the summarized output video\n",
        "        create_summarized_video(input_video_path, output_video_path, selected_frames)\n",
        "\n",
        "        print(\"Video summarization completed successfully!\")\n",
        "    except ValueError as e:\n",
        "        print(f\"Video summarization failed: {str(e)}\")\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    return elapsed_time"
      ],
      "metadata": {
        "id": "Ly010-D8LUdZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_space_complexity():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    memory_usage = process.memory_info().rss  # in bytes\n",
        "    memory_usage_mb = memory_usage / (1024 ** 2)  # convert to megabytes\n",
        "    return memory_usage_mb"
      ],
      "metadata": {
        "id": "Poqhj3AOLYw5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    time_complexity = get_time_complexity()\n",
        "    space_complexity = get_space_complexity()\n",
        "\n",
        "    print(f\"Overall Time Complexity: {time_complexity} seconds\")\n",
        "    print(f\"Overall Space Complexity: {space_complexity} MB\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHhsfq3oLbPB",
        "outputId": "ba1e72fe-f934-4de1-8ce8-3dcffffa8c2c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video summarization failed: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 16777216 and the array at index 1 has size 460800\n",
            "Overall Time Complexity: 43.7524197101593 seconds\n",
            "Overall Space Complexity: 183.9609375 MB\n"
          ]
        }
      ]
    }
  ]
}